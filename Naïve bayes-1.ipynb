{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe04e8-51d0-4d14-9285-de342ec78274",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Bayes' theorem? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0017c431-19de-4b52-b4d1-89252973846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans :Bayes' theorem, named after the 18th-century statistician and philosopher Thomas Bayes, is a fundamental principle in \n",
    "     probability theory and statistics. It provides a way to update the probability for a hypothesis as more evidence or\n",
    "     information becomes available.\n",
    "\n",
    "    Bayes' theorem is expressed mathematically as follows:\n",
    "    \n",
    "    P(A|B) = ( P(B|A) * P(A) ) / P(B)\n",
    "    \n",
    "    Where:\n",
    "\n",
    "        P(A∣B) is the conditional probability of event A given event B (the probability of A happening when B is true).\n",
    "        P(B∣A) is the conditional probability of event B given event A (the probability of B happening when A is true).\n",
    "        P(A) is the prior probability of event A (the probability of A happening before considering evidence B).\n",
    "        P(B) is the prior probability of event B (the probability of B happening before considering evidence A).\n",
    "        \n",
    "        n words, Bayes' theorem states that the probability of A happening given that B has occurred is proportional to the probability \n",
    "        of B happening given that A has occurred, multiplied by the prior probability of A, and divided by the prior probability of B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a20223-b472-4e54-bd1e-f94fcf0c9916",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f1a71c-6381-4fa4-a4eb-300ed8e1efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans : P(A|B) = ( P(B|A) * P(A) ) / P(B)\n",
    "    \n",
    "    Where:\n",
    "\n",
    "        P(A∣B) is the conditional probability of event A given event B (the probability of A happening when B is true).\n",
    "        P(B∣A) is the conditional probability of event B given event A (the probability of B happening when A is true).\n",
    "        P(A) is the prior probability of event A (the probability of A happening before considering evidence B).\n",
    "        P(B) is the prior probability of event B (the probability of B happening before considering evidence A).\n",
    "        \n",
    "        n words, Bayes' theorem states that the probability of A happening given that B has occurred is proportional to the probability \n",
    "        of B happening given that A has occurred, multiplied by the prior probability of A, and divided by the prior probability of B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974d0d9-1ba9-4ec2-bd46-d6cd98189138",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17764fa8-1150-4e2f-a797-1b087fd761a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans : Bayes' theorem is used in practice in a wide range of fields and applications to solve problems that involve probabilistic reasoning,\n",
    "      evidence-based decision-making, and updating beliefs in light of new information. \n",
    "    Here's how Bayes' theorem is applied in various practical contexts:\n",
    "        \n",
    "        1. Medical Diagnosis: Bayes' theorem is used in medical diagnosis to estimate the probability of a disease given a set of \n",
    "           symptoms and test results. Doctors use prior knowledge about the prevalence of the disease, the accuracy of the diagnostic \n",
    "            tests, and the patient's symptoms to make more accurate diagnoses.\n",
    "\n",
    "        2. Spam Email Filtering: Email services employ Bayesian spam filters that use Bayes' theorem to classify incoming emails \n",
    "           as spam or not. The filter learns from a dataset of known spam and non-spam emails and updates its probability model to\n",
    "            classify new emails based on their content.\n",
    "\n",
    "        3. Machine Learning: In machine learning, particularly Bayesian machine learning, Bayes' theorem is used for probabilistic\n",
    "           modeling and inference. Bayesian methods are applied in regression, classification, clustering, and more. They provide \n",
    "            a framework for estimating parameters and making predictions while quantifying uncertainty.\n",
    "        \n",
    "        4.  Natural Language Processing: Bayes' theorem is used in various natural language processing tasks, such as text classification,\n",
    "            sentiment analysis, and named entity recognition. It helps model the conditional probabilities of words or phrases given certain \n",
    "            categories or contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe91808c-978c-40fd-a464-05601b0c55e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4e1b2f-7015-4952-9c9d-dba0b7ed6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans : The relationship between Bayes' theorem and conditional probability can be understood by examining the components of the theorem.\n",
    "      \n",
    "     P(A|B) = ( P(B|A) * P(A) ) / P(B)\n",
    "    \n",
    "    Where:\n",
    "\n",
    "        P(A∣B) is the conditional probability of event A given event B (the probability of A happening when B is true).\n",
    "        P(B∣A) is the conditional probability of event B given event A (the probability of B happening when A is true).\n",
    "        P(A) is the prior probability of event A (the probability of A happening before considering evidence B).\n",
    "        P(B) is the prior probability of event B (the probability of B happening before considering evidence A).\n",
    "        \n",
    "        The relationship with conditional probability is evident in the left side of the equation (P(A∣B)), which represents \n",
    "        the conditional probability. Bayes' theorem allows us to calculate this conditional probability using the prior probabilities \n",
    "        P(A) and P(B), and the conditional probabilities P(B∣A).\n",
    "        \n",
    "        In words, Bayes' theorem tells us that the conditional probability of event A given event B is proportional to the\n",
    "        conditional probability of event B given event A, multiplied by the prior probability of event A, and divided by the\n",
    "        prior probability of event B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac572a6-0c4e-4ab7-82c2-9cc35ca0f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d5578-1019-48eb-aeda-679c72ccd93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans : Choosing the most appropriate type of Naive Bayes classifier for a given problem depends on the nature of the problem \n",
    "      and the characteristics of the data. There are three common types of Naive Bayes classifiers: Gaussian Naive Bayes, \n",
    "      Multinomial Naive Bayes, and Bernoulli Naive Bayes. \n",
    "        Here's a guideline on how to choose the right type:\n",
    "        1. Gaussian Naive Bayes:\n",
    "\n",
    "            a. Continuous Data: Use Gaussian Naive Bayes when your data features are continuous and can be modeled as following a\n",
    "               Gaussian (normal) distribution. This classifier assumes that each feature follows a normal distribution.\n",
    "            b. Real-Valued Features: It's suitable for problems with real-valued features, such as sensor readings, measurements, \n",
    "               or any data that can take on a wide range of numeric values.\n",
    "                \n",
    "        2 . Multinomial Naive Bayes:\n",
    "\n",
    "            a. Categorical Data: Use Multinomial Naive Bayes when your data represents counts or frequencies of events. It's commonly \n",
    "               used for text classification problems where features are word frequencies (bag of words).\n",
    "            b. Discrete Features: It's suitable for problems with discrete features, such as document classification, spam detection,\n",
    "               or any task where you're dealing with counts of occurrences.\n",
    "                \n",
    "        3. Bernoulli Naive Bayes:\n",
    "\n",
    "            a. Binary Data: Use Bernoulli Naive Bayes when your features are binary (yes/no, 1/0) or represent the presence or absence \n",
    "               of specific characteristics.\n",
    "            b. Text Classification: It's commonly used for text classification tasks where features indicate the presence (1) or absence\n",
    "               (0) of specific words in documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a852a6-5977-451c-80b1-feaca1091c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6398a6-b0db-4ff4-82ca-04825d3e6884",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans : To classify a new instance with features X1 = 3 and X2 = 4 using Naive Bayes, we need to calculate the posterior probabilities \n",
    "      for each class (A and B) and then choose the class with the highest posterior probability.\n",
    "\n",
    "    1. Class A:\n",
    "\n",
    "          Prior Probability (P(A)): Since we're assuming equal prior probabilities for each class,\n",
    "            P(A) = P(B) = 0.5.\n",
    "          Likelihood (P(X1=3|A) * P(X2=4|A)): From the table, we can see that for Class A,\n",
    "                  P(X1=3|A) = 4/10 and P(X2=4|A) = 3/10.\n",
    "          Multiply the prior probability by the likelihood:\n",
    "             P(A)∗P(X1=3∣A)∗P(X2=4∣A)=0.5∗(4/10)∗(3/10)=0.06.\n",
    "                \n",
    "    2 . Class B:\n",
    "\n",
    "        Prior Probability (P(B)): Since we're assuming equal prior probabilities for each class,\n",
    "              P(A) = P(B) = 0.5.\n",
    "        Likelihood (P(X1=3|B) * P(X2=4|B)): From the table, we can see that for Class B,\n",
    "             P(X1=3|B) = 1/7 and P(X2=4|B) = 3/7.\n",
    "        Multiply the prior probability by the likelihood: \n",
    "             P(B)∗P(X1=3∣B)∗P(X2=4∣B)=0.5∗(1/7)∗(3/7)=0.032142857.\n",
    "                \n",
    "                Now, we compare the posterior probabilities for Class A and Class B:\n",
    "\n",
    "                    Posterior Probability for Class A = 0.06\n",
    "                    Posterior Probability for Class B = 0.032142857\n",
    "                    Since the posterior probability for Class A (0.06) is greater than the posterior probability for\n",
    "                    Class B (0.032142857), Naive Bayes would predict that the new instance with features X1 = 3 and X2 = 4 belongs to Class A."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
